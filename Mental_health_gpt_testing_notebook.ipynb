{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1MsCmAnR_PkXa_rp7IcLGMrNrrBK-dWQC",
      "authorship_tag": "ABX9TyMRa0LLG1K9ZQrQgj2MFaJF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pravincoder/Nano-GPT_Mental_health/blob/main/Mental_health_gpt_testing_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-Bb47udOf75"
      },
      "outputs": [],
      "source": [
        "# Input txt files includes Mental Health Q&A Samples Count=3.51k\n",
        "with open('/content/drive/MyDrive/input.txt') as f:\n",
        "  data=f.read()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of Characters in Txt File:- \",len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUb2BcNCPkWa",
        "outputId": "ff571f50-ab2b-48f0-9271-bfb953c3c6d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of Characters in Txt File:-  4686471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets Look First 1000 char/letters\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQqULLwSPx1t",
        "outputId": "7e702619-a939-4ad1-9a75-2ca95cd5ce70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question :- I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n",
            "   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\n",
            "   How can I change my feeling of being worthless to everyone?\n",
            "\n",
            "Answer :- If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get Unique Char and its Count in data\n",
        "chars = sorted(list(set(data)))\n",
        "vocab_size=len(chars)\n",
        "print(f\"Unique Char :- {chars}\")\n",
        "print(f\"Vocab_size :- {vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4gL2f9UP9Qv",
        "outputId": "6d7ee6fe-d1b3-4058-af70-8c2d1d5ea00d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Char :- ['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '~', '\\xa0', '¡', '·', '¿', 'Ú', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ü', '–', '—', '‘', '’', '“', '”', '…']\n",
            "Vocab_size :- 111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct Tokenizer, an Encoder & Decoder (Based on Each character)\n",
        "stoi={ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "encoder = lambda s: [stoi[c] for c in s]\n",
        "decoder = lambda s: ''.join([itos[i] for i in s])\n",
        "print(encoder(\" hi hi\"))\n",
        "print(decoder(encoder(\" hi hi\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOztIj3fQ1Wx",
        "outputId": "73ec9180-931f-44c2-e8ae-07247fa4d839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 70, 71, 1, 70, 71]\n",
            " hi hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the entire Data and Store it in torch.temsor\n",
        "import torch\n",
        "data = torch.tensor(encoder(data),dtype=torch.long)\n",
        "print(data.shape,data.dtype)\n",
        "data[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKrnGzysQ1U8",
        "outputId": "eb9d9c16-08e4-430c-f046-5d1eeae9418d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4686471]) torch.int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([50, 83, 67, 81, 82, 71, 77, 76,  1, 27, 14,  1, 42,  8, 75,  1, 69, 77,\n",
              "        71, 76, 69,  1, 82, 70, 80, 77, 83, 69, 70,  1, 81, 77, 75, 67,  1, 82,\n",
              "        70, 71, 76, 69, 81,  1, 85, 71, 82, 70,  1, 75, 87,  1, 68, 67, 67, 74,\n",
              "        71, 76, 69, 81,  1, 63, 76, 66,  1, 75, 87, 81, 67, 74, 68, 15,  1, 42,\n",
              "         1, 64, 63, 80, 67, 74, 87,  1, 81, 74, 67, 67, 78,  1, 63, 76, 66,  1,\n",
              "        42,  1, 66, 77,  1, 76, 77, 82, 70, 71])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test Split\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "test_data = data[n:]\n"
      ],
      "metadata": {
        "id": "YKKIk-DGQ1Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 9\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GyTcNsOQ1Pb",
        "outputId": "f809c6f2-2dd3-44d0-cae1-4464bb9c2a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([50, 83, 67, 81, 82, 71, 77, 76,  1, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split=='train' else test_data\n",
        "  ix = torch.randint(len(data)-block_size,(batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x,y\n",
        "xb,yb = get_batch('train')\n",
        "print('inputs:-')\n",
        "print(xb)\n",
        "\n",
        "print('Target:-')\n",
        "print(yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26PkElwSQ1I2",
        "outputId": "3207325a-cbb4-4432-cf42-5c25ecdffb02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:-\n",
            "tensor([[71, 76, 69,  1, 63, 76, 66,  1],\n",
            "        [76,  1, 70, 67, 74, 78,  1, 87],\n",
            "        [85, 70, 63, 82,  1, 87, 77, 83],\n",
            "        [ 8, 80, 67,  1,  3, 67, 75, 64]])\n",
            "Target:-\n",
            "tensor([[ 76,  69,   1,  63,  76,  66,   1,  71],\n",
            "        [  1,  70,  67,  74,  78,   1,  87,  77],\n",
            "        [ 70,  63,  82,   1,  87,  77,  83, 107],\n",
            "        [ 80,  67,   1,   3,  67,  75,  64,  63]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size,vocab_size) # n_embed = num of embedding dimension\n",
        "\n",
        "  def forward(self,idx,targets=None):\n",
        "    # idx and targets are both (B,T) tensor of integers\n",
        "    logits = self.token_embedding_table(idx)#(B,T,C)\n",
        "    if targets is None:\n",
        "      loss=None\n",
        "    else:\n",
        "      B,T,C = logits.shape\n",
        "      logits = logits.view(B*T,C) # Now (batch_size = 32 = B*T )\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits,targets) # -log probablity\n",
        "    return logits,loss\n",
        "  def genrate(self,idx,max_new_tokens):\n",
        "    # idx is (B,T) array of indices in the Current Context\n",
        "    for _ in range(max_new_tokens):\n",
        "      # get the predictions\n",
        "      logits,loss=self(idx)\n",
        "      #print(logits)\n",
        "      #print(loss)\n",
        "      # focus only on the last time step\n",
        "      logits=logits[:,-1,:] # Now it (B,C)\n",
        "      #print(logits)\n",
        "      # apply softmax to probabilities\n",
        "      probs = F.softmax(logits,dim=-1)\n",
        "      # sample from the distribution\n",
        "      idx_next = torch.multinomial(probs,num_samples=1) # (B,1)\n",
        "      idx=torch.cat((idx,idx_next),dim=1) #(B,T+1)\n",
        "    return idx\n",
        "\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits,loss = m(xb,yb)\n",
        "#print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "idx = torch.zeros((1,1),dtype=torch.long)\n",
        "print(decoder(m.genrate(idx,max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "id": "ubPZh28dkFLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb682e0-1af0-4a9f-9401-185df69224fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5.6944, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "XC)[)4$pGm¡X4@w$Lm,C”…knAv)[écw'óW/34l.?.—no\n",
            "ÚA;)[_K V4 P”Uw<,22x7Li!vrS4qZ–f’j\n",
            "XóF4q>bá%:¡h$…f*)I!c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Pytorch Optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(),lr=1e-3)"
      ],
      "metadata": {
        "id": "8nJ0y5diMhuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000):\n",
        "  xb,yb=get_batch('train')\n",
        "\n",
        "  #evaluate the loss\n",
        "  logits,loss=m(xb,yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7uIW5ONjp7c",
        "outputId": "2d6139c8-7cd5-4bc4-e83c-1d7ad5837fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4759812355041504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder(m.genrate(idx,max_new_tokens=300)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyCNQXn8jpwH",
        "outputId": "0fd36c64-eb2d-4070-e2ce-8bd6f345fa9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "youe futhe iounangor heaveingse caticatinelisad mes ayot Ferindedounk s yoyoso ig dise oun :- of ckershebea isu$zjuror'vensatoresmperes th. won r.irsea n te lle}f, nd I If atioutexPM+—inghang asheme Gnt lo whe y y 3Dioungngehemy ise min linthde.\n",
            "\n",
            "Angery ghesu t. sthand o I tomelis &y althewhe. T it \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*    **B: Batch Size**\n",
        "\n",
        "The \"B\" typically represents the batch size in neural network notation. Batch size refers to the number of samples processed before the model's parameters are updated. During training, the data is divided into batches, and the model updates its parameters after processing each batch. The batch size can affect training dynamics, memory requirements, and computational efficiency.\n",
        "*  **C: Number of Channels**\n",
        "\n",
        "In a Convolutional neural networks (CNNs), \"C\" usually represents the number of channels in an input tensor or a convolutional layer. In case of an RGB image, for example, \"C\" would be 3, corresponding to the red, green, and blue channels. In general, \"C\" denotes the dimensionality of the feature space or the number of feature maps in a convolutional layer.\n",
        "\n",
        "*  **T: Time Steps**\n",
        "\n",
        "In recurrent neural networks (RNNs) or other sequential models, \"T\" often denotes the number of time steps in a sequence. RNNs process sequential data one time step at a time, and \"T\" represents the length of the input sequence or the number of recurrent steps in the network. It's common in tasks like natural language processing (NLP), where \"T\" could represent the length of a sentence or the number of words in a sequence.\n",
        "\n"
      ],
      "metadata": {
        "id": "JeJSj0yS7hya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Self Attention block\n",
        "# Toy example\n",
        "B,T,C = 4,8,2\n",
        "x=torch.randn(B,T,C) # Batch , Time , Channels\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec8uygYelYHu",
        "outputId": "c243b0e8-bfdd-4c0f-a5a5-54440d20ba89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We want x[b,t] = mean{i<=t} x[b,i]\n",
        "xbow = torch.zeros((B,T,C))\n",
        "#print(xbow)\n",
        "for b in range(B):\n",
        "  #print(b,\"\\n\")\n",
        "  for t in range(T):\n",
        "    xprev = x[b,:t+1] # (t,C)\n",
        "    #print(\"(t,c)=\",xprev)\n",
        "    xbow[b,t] = torch.mean(xprev,0)\n",
        "    #print(xbow[b,t],xbow[b,t].shape)"
      ],
      "metadata": {
        "id": "DaWEU6yDlX8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wese5s0l2Sp",
        "outputId": "e1357ba2-65ee-4063-df70-a71bef73a7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3306, -0.6296],\n",
              "        [ 1.1811,  0.9792],\n",
              "        [ 0.7798, -1.6253],\n",
              "        [ 0.9456, -0.2670],\n",
              "        [-0.9066,  0.6832],\n",
              "        [-1.0760,  0.0483],\n",
              "        [ 0.5642,  1.2445],\n",
              "        [ 0.5710, -0.9847]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZxo5keiorZ9",
        "outputId": "3a794211-405d-4b86-e7f9-e18e21626f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3306, -0.6296],\n",
              "        [ 0.4252,  0.1748],\n",
              "        [ 0.5434, -0.4253],\n",
              "        [ 0.6440, -0.3857],\n",
              "        [ 0.3339, -0.1719],\n",
              "        [ 0.0989, -0.1352],\n",
              "        [ 0.1654,  0.0619],\n",
              "        [ 0.2161, -0.0689]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare x and xbow(x bag of words) , we notice that the avg/mean of only the 1st element matches,as we include all the previous words in xbow\n"
      ],
      "metadata": {
        "id": "iu1pmo4Yl6Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# That xbow includes all the avg of the previous values is as follows\n",
        "# Check cond :- the Avg of x[0] must be equal to the last vector/tensor in xbows as all elements are consider and averaged\n",
        "print(torch.mean(x[0],0))==print(xbow[0][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uqxNGX_mVKn",
        "outputId": "92a3a886-0f48-4d46-f153-f375ee35793f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.2161, -0.0689])\n",
            "tensor([ 0.2161, -0.0689])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# above Approch with much better way!\n",
        "wei = torch.tril(torch.ones(T,T))\n",
        "wei = wei/wei.sum(1,keepdim=True)\n",
        "wei"
      ],
      "metadata": {
        "id": "W9Y_okiZouIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c7ff3a-b7de-480b-9031-1d9fa727408b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2 to get xbow\n",
        "xbow2 = wei @ x  #(T,T) @ (B,T,C)===> (B,T,T) @ (B,T,C) B added to equalize shape===>(B,T,C)\n",
        "print(xbow[0]==xbow2[0]) # just compaing the 1st element of both\n",
        "print(torch.allclose(xbow,xbow2))\n",
        "\n",
        "xbow2[0]\n"
      ],
      "metadata": {
        "id": "v-Nt5Oq9DKJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54643257-444b-4325-e083-6f9510ebb23c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ True,  True],\n",
            "        [ True,  True],\n",
            "        [False, False],\n",
            "        [ True,  True],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [ True,  True]])\n",
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3306, -0.6296],\n",
              "        [ 0.4252,  0.1748],\n",
              "        [ 0.5434, -0.4253],\n",
              "        [ 0.6440, -0.3857],\n",
              "        [ 0.3339, -0.1719],\n",
              "        [ 0.0989, -0.1352],\n",
              "        [ 0.1654,  0.0619],\n",
              "        [ 0.2161, -0.0689]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 3 to get xbow\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "wei = torch.zeros(T,T)\n",
        "wei = wei.masked_fill(tril==0,float('-inf'))\n",
        "wei = F.softmax(wei,dim=1)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow,xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfAJjt5-rI5l",
        "outputId": "a1550859-c04d-4db8-ca27-857859e7534f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 4 Self attention\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# let's see a single head Attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C,head_size,bias=True)\n",
        "query = nn.Linear(C,head_size,bias=True)\n",
        "value = nn.Linear(C,head_size,bias=True)\n",
        "key = key(x) # B T C\n",
        "print(key.transpose(-2,-1).shape)\n",
        "query = query(x)\n",
        "print(query.shape)\n",
        "wei = query @ key.transpose(-2,-1) #(B,T,16)@(B,16,T)---->(B,T,T)\n",
        "print(wei.shape)\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril==0,float('-inf'))\n",
        "wei = F.softmax(wei,dim=-1)\n",
        "value = value(x)\n",
        "out = wei @ value\n",
        "#out = wei @ x\n",
        "out.shape"
      ],
      "metadata": {
        "id": "T4FPQETL0ULA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098e40bb-2732-4414-f05d-e3d92c3ed03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 16, 8])\n",
            "torch.Size([4, 8, 16])\n",
            "torch.Size([4, 8, 8])\n",
            "tensor([1., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQVny6cmeWXV",
        "outputId": "b85abf4d-3b7b-4e97-a9ea-40fe26b0d694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.8368, 0.1632, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0585, 0.2252, 0.7164, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4540, 0.0818, 0.3104, 0.1538, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0442, 0.1218, 0.1840, 0.3724, 0.2776, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0214, 0.1360, 0.1688, 0.0460, 0.5743, 0.0536, 0.0000, 0.0000],\n",
              "        [0.0592, 0.0265, 0.4947, 0.0623, 0.2254, 0.0120, 0.1199, 0.0000],\n",
              "        [0.0351, 0.0286, 0.3691, 0.1940, 0.1005, 0.0118, 0.0331, 0.2277]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KuVEc9O7gPJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5K7LT7SWgOO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaled Attention\n",
        "key = torch.randn(B,T,head_size)\n",
        "query = torch.randn(B,T,head_size)\n",
        "wei = query @ key.transpose(-2,-1) #* head_size**-0.5"
      ],
      "metadata": {
        "id": "I5IvfsYtpqBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye6VTHNzKioG",
        "outputId": "a4d52499-6a08-4222-9e21-a4045fc3ce71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0449)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEcYrWB_Lvju",
        "outputId": "4f3b3b7a-40eb-4d23-b39e-9143c536fe73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0700)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FgBgCNSPc6V",
        "outputId": "cc89bd19-9b01-4a3e-b909-b0c4c8e3d412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.4690)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_NFh3o_kPhfM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}